;[FL_Service]
service_id = 0
; 리더 수
leader = 1
; Aggregator 수
aggregator = 2
; 유저셋 수
userset = 4
; 유저 수
user = 50
; simulate(True, False) : True시, 계층간 통신 없는 시뮬레이션 실행
simulate = False
; end_condition[ROUND, ACC(%)] : 몇 ROUND, ACC 몇 % 에서 멈출지 선택 
end_condition = 5, 100
; exp_name/group_name : wandb에 저장될 그룹과 실험의 이름
exp_name = RPC_test
group_name = RPC_TEST

;[Model_Data]
; model(mcmahan2NN, mcmahanCNN, resnet50, resnet101, densenet121, VGG16) : 모델 세팅
model = mcmahan2NN
; pretrained(True, False) : 모델의 pretrained 여부(resnet50/101, densenet121, VGG16에서만 작동)
pretrained = True
; optimizer(adam, SGD) : Optimizer 세팅
optimizer = adam

;[Aggregation_Method]
; agg_method, add_agg_method[METHOD , WEIGHT]
; METHOD(Equal, Acc, F1macro, F1micro, Fedavg, FedAT) : 집계 방법
; WEIGHT : 해당 집계 방법의 가중치(%)
agg_method = Fedavg, 40
add_agg_method1 = Equal, 40
add_agg_method2 = Acc, 20
; adaptive_agg_method(no_adapt, Epoch, Acc) : Epoch/Acc 선택 시, adaptive_parameter에 따라 집계방법 전환
; adaptive_agg_method = Acc, adaptive_parameter = 50 >> Test Acc가 50%를 넘기기 이전에는 'Fedavg', 넘긴 다음 라운드부터는 agg_method의 METHOD
adaptive_agg_method = no_adapt
adaptive_parameter = 40
; fraction : 학습에 참여하는 유저의 퍼센트 
fraction = 100
compress = nomal|wt|wd|wdtop|lwdtop, 10

;[Hyper_Parameter]
; aggregator_round : 유저셋의 학습 모델을 모으는 횟수
aggregator_round = 1
; local_epoch : 유저셋의 학습 횟수
local_epoch = 2
; local_batch_size : 모델 학습시 batch size
local_batch_size = 256
; local_learning_rate : 모델 학습시 learning rate
local_learning_rate = 0.001
; evaluate_batch_size : 모델 평가시 batch size
evaluate_batch_size = 64
lr_decay = 0.99
lr_decay_round = 5

;[Data_Split]
; dataset(mnist, cifar10) : 데이터셋 세팅
dataset = mnist
; data_split(random, iid, non_iid, diri, diff) : 데이터 분산 방법
data_split = iid
; diri_alpha(0 초과, 30 미만 값 권장) : (data_split : diri)에서의 편향도 조절값(작을수록 편향도가 커진다)
diri_alpha = 3
; byzantine(True, False) :  True시, 유저는 본인 데이터 중 1%만은 이용해 학습 진행
byzantine = False
; force_num : 0이 아닌 경우, 해당 개수만큼 학습 데이터를 제한(단, force_num 개수가 학습 데이터 개수보다 크면 적용되지 않음)
force_num = 0

;[Simulate_Parameter]
; agg_delays(aggregator 개수만큼 입력) : aggregator의 티어(글로벌 업데이트 지연 라운드)
agg_delays = 0,0,0,0,0,0,0,0,0,0
; client_mapping(Equal, diff) : aggregator마다 유저수를 Equal/different하게 분배
user_mapping = equal
; delay_method(Range, Fixed) : (Fixed) agg_delays가 매 라운드 동등, (Range) agg_delays가 매 라운드마다 delay_range 사이 에서 정해진다
delay_method = Range
delay_range = 2
; delay_epoch : 해당 글로벌 업데이트에 참여하지 못한 aggregator가 추가로 수행할 로컬 업데이트 횟수
delay_epoch = 0
; 글로벌 Test Acc를 산출하는 주기(round)
eval_every = 1
; model_decay(Equal, Frac) : ??
model_decay = Equal
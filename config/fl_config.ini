[FL_Service]
# TODO: lr,opt는 작동X(lr_decay,lr_decay_round는 Simulation 코드에서만 돌아감)
# FIXME: diri split 코드 오작동 이슈
# simulate=True는 쉽게 UNIST 용역 코드(Manager,Client,Leader만 있으면 작동), False는 ETRI 코드(Manager,Client,Leader,Aggregator,Userset이 다 있어야 작동)
# hybrid는 김동오 박사님이 agg method를 섞을 수 없냐해서 만든 가중치 합산하는 코드임. False로 해두고 실험 진행할 것

service_id = 0
; 리더 수
leader = 1
; Aggregator 수
aggregator = 1
; 유저셋 수
userset = 1
; 유저 수
user = 2
; simulate(True, False) : True시, 계층간 통신 없는 시뮬레이션 실행
simulate = False
; end_condition[ROUND, ACC(%)] : 몇 ROUND, ACC 몇 % 에서 멈출지 선택 
end_condition = 2, 100
; ipfs(True, False) : True의 경우 학습 모델의 가중치를 ipfs에 저장 및 불러오기
ipfs = False

# ====== Wandb Setting ======
# wandb = True
# wandb_id = create0327
# wandb_api = b2f21ce10a4365a21cfce06ad41f9a7f23d34639
# group_name = UNIST_TEST
#exp_name = 0. Debug

# ====== Model Setting ======
; model(mcmahan2NN, mcmahanCNN, resnet50, resnet101, densenet121, VGG16) : 모델 세팅
model = mcmahan2NN
; pretrained(True, False) : 모델의 pretrained 여부(resnet50/101, densenet121, VGG16에서만 작동)
pretrained = False
; optimizer(adam, SGD) : Optimizer 세팅
optimizer = SGD

# ====== Data Setting ======
; dataset(mnist, cifar10) : 데이터셋 세팅
dataset = mnist
; data_split(random, iid, non_iid, diri, diff) : 데이터 분산 방법
data_split = random
; diri_alpha(0 초과, 30 미만 값 권장) : (data_split : diri)에서의 편향도 조절값(작을수록 편향도가 커진다)
diri_alpha = 1
; byzantine(True, False) :  True시, 유저는 본인 데이터 중 1%만은 이용해 학습 진행

# ====== Aggregation Method Setting ======
hybrid = False
agg_method = Fedavg
adaptive_agg_method = no_adapt
adaptive_parameter = 40

# ====== Hyper parameter Setting ======
; aggregator_round : 유저셋의 학습 모델을 모으는 횟수
aggregator_round = 1
; local_epoch : 유저셋의 학습 횟수
local_epoch = 5
; local_batch_size : 모델 학습시 batch size
local_batch_size = 64
; local_learning_rate : 모델 학습시 learning rate
local_learning_rate = 0.001
; evaluate_batch_size : 모델 평가시 batch size
evaluate_batch_size = 64
lr_decay = 0.99
lr_decay_round = 5

# ====== Simulator parameter Setting ======
classification = n_data
; agg_delays(aggregator 개수만큼 입력) : aggregator의 티어(글로벌 업데이트 지연 라운드)
agg_delays = 0,0,0,0,0,0,0,0,0,0
; client_mapping(Equal, diff) : aggregator마다 유저수를 Equal/different하게 분배
user_mapping = equal
; delay_method(Range, Fixed) : (Fixed) agg_delays가 매 라운드 동등, (Range) agg_delays가 매 라운드마다 delay_range 사이 에서 정해진다
delay_method = Fixed
delay_range = 2
; delay_epoch : 해당 글로벌 업데이트에 참여하지 못한 aggregator가 추가로 수행할 로컬 업데이트 횟수
delay_epoch = 0
; 글로벌 Test Acc를 산출하는 주기(round)
eval_every = 1
; model_decay(Equal, Frac) : ??
model_decay = Equal